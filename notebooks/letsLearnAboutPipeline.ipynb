{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnnscrapercondaa354d8fb32614818906b42d96b0e4fbd",
   "display_name": "Python 3.8.5 64-bit ('NNScraper': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# custom made functions (can be a pain to import sometimes)\n",
    "import sys\n",
    "sys.path.insert(0,os.path.abspath('../src/helper'))\n",
    "from customPandas import *\n",
    "#saving the model\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "source": [
    "## Loading the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/39125532/file-does-not-exist-in-jupyter-notebook\n",
    "dataPath = os.path.abspath('../data')\n",
    "fileName = 'ramen-ratings.csv'\n",
    "df = pd.read_csv(f'{dataPath}/{fileName}') "
   ]
  },
  {
   "source": [
    "## Cleaning some of the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Series([], Name: Stars, dtype: object)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "def cleanStars(value):\n",
    "    if value == 'Unrated':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return value\n",
    "df.Stars = df.Stars.apply(cleanStars) \n",
    "df[df.Stars == 'Unrated'].Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Review #','Top Ten'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Total, Percent]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>Percent</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "totalPercentageNullData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing an incorrect dtype\n",
    "df = df.astype({'Stars':'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Stars\n",
       "count  2580.000000\n",
       "mean      3.654884\n",
       "std       1.014886\n",
       "min       0.000000\n",
       "25%       3.250000\n",
       "50%       3.750000\n",
       "75%       4.250000\n",
       "max       5.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Stars</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2580.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.654884</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.014886</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.250000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.750000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.250000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Stars']\n",
    "df = df.drop(['Stars'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Brand                                Variety Style      Country\n",
       "47    Nongshim                      Shin Ramyun Black  Pack  South Korea\n",
       "76    Nongshim                            Shin Ramyun  Pack  South Korea\n",
       "1017  Nongshim  Shin Ramyun Noodle Soup (New Edition)  Pack          USA\n",
       "1393  Nongshim                        Shin Ramyun Cup   Cup  South Korea\n",
       "1536  Nongshim      Shin Ramyun Noodle Spicy Mushroom  Bowl        China\n",
       "1582  Nongshim           Shin Ramyun Black Spicy Beef   Cup  South Korea\n",
       "1829  Nongshim                Shin Ramyun Black Onion   Cup  South Korea\n",
       "1903  Nongshim                     Shin Ramyun Shrimp  Pack        China\n",
       "2002  Nongshim                      Shin Ramyun Black  Pack  South Korea\n",
       "2561  Nongshim                            Shin Ramyun  Pack  South Korea"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Brand</th>\n      <th>Variety</th>\n      <th>Style</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>47</th>\n      <td>Nongshim</td>\n      <td>Shin Ramyun Black</td>\n      <td>Pack</td>\n      <td>South Korea</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>Nongshim</td>\n      <td>Shin Ramyun</td>\n      <td>Pack</td>\n      <td>South Korea</td>\n    </tr>\n    <tr>\n      <th>1017</th>\n      <td>Nongshim</td>\n      <td>Shin Ramyun Noodle Soup (New Edition)</td>\n      <td>Pack</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <th>1393</th>\n      <td>Nongshim</td>\n      <td>Shin Ramyun Cup</td>\n      <td>Cup</td>\n      <td>South Korea</td>\n    </tr>\n    <tr>\n      <th>1536</th>\n      <td>Nongshim</td>\n      <td>Shin Ramyun Noodle Spicy Mushroom</td>\n      <td>Bowl</td>\n      <td>China</td>\n    </tr>\n    <tr>\n      <th>1582</th>\n      <td>Nongshim</td>\n      <td>Shin Ramyun Black Spicy Beef</td>\n      <td>Cup</td>\n      <td>South Korea</td>\n    </tr>\n    <tr>\n      <th>1829</th>\n      <td>Nongshim</td>\n      <td>Shin Ramyun Black Onion</td>\n      <td>Cup</td>\n      <td>South Korea</td>\n    </tr>\n    <tr>\n      <th>1903</th>\n      <td>Nongshim</td>\n      <td>Shin Ramyun Shrimp</td>\n      <td>Pack</td>\n      <td>China</td>\n    </tr>\n    <tr>\n      <th>2002</th>\n      <td>Nongshim</td>\n      <td>Shin Ramyun Black</td>\n      <td>Pack</td>\n      <td>South Korea</td>\n    </tr>\n    <tr>\n      <th>2561</th>\n      <td>Nongshim</td>\n      <td>Shin Ramyun</td>\n      <td>Pack</td>\n      <td>South Korea</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "df[df['Brand'].isin(['Nongshim']) & df['Variety'].str.contains('Shin Ramyun')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Variety  Style  Country\n",
       "Brand                                    \n",
       "1 To 3 Noodles          1      1        1\n",
       "7 Select                2      2        2\n",
       "7 Select/Nissin         1      1        1\n",
       "A-One                   4      4        4\n",
       "A-Sha Dry Noodle       26     26       26\n",
       "...                   ...    ...      ...\n",
       "Yum Yum                12     12       12\n",
       "Yum-Mie                 1      1        1\n",
       "Zow Zow                 1      1        1\n",
       "iMee                    4      4        4\n",
       "iNoodle                 2      2        2\n",
       "\n",
       "[355 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Variety</th>\n      <th>Style</th>\n      <th>Country</th>\n    </tr>\n    <tr>\n      <th>Brand</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1 To 3 Noodles</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7 Select</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7 Select/Nissin</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>A-One</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>A-Sha Dry Noodle</th>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Yum Yum</th>\n      <td>12</td>\n      <td>12</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>Yum-Mie</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Zow Zow</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>iMee</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>iNoodle</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>355 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "df.groupby(by=['Brand']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       3.75\n",
       "1       1.00\n",
       "2       2.25\n",
       "3       2.75\n",
       "4       3.75\n",
       "        ... \n",
       "2575    3.50\n",
       "2576    1.00\n",
       "2577    2.00\n",
       "2578    2.00\n",
       "2579    0.50\n",
       "Name: Stars, Length: 2580, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "source": [
    "## Custom Transformers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "def nltkPreprocess(text):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        - Takes a text and cleans it by removing useless punctuations and stopwords\n",
    "    input:\n",
    "        -string\n",
    "    output:\n",
    "        - list of strings\n",
    "    \"\"\"\n",
    "    # lower\n",
    "    words = text.lower().split()\n",
    "    # remove punctiuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in words]\n",
    "    #remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    clean = [w for w in stripped if not w in stop_words if len(w)>2]\n",
    "    return clean \n",
    "\n",
    "\n",
    "def cleanVariety(col):\n",
    "    \"\"\"\n",
    "    description:\n",
    "        - adaptation for \n",
    "    \"\"\"\n",
    "    cleanCol = list()\n",
    "    # print(col)\n",
    "    for v in col:\n",
    "        # print(type(v))\n",
    "        cleanCol.append(nltkPreprocess(v[0]))\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are trying to make feature engineering part of our pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#! because the way .fit works in sklearn it passes the arrays as np.array so you must specify\n",
    "mapper = ColumnTransformer(transformers=[\n",
    "('Variety', FunctionTransformer(cleanVariety, validate=False),[1])], remainder='passthrough')\n"
   ]
  },
  {
   "source": [
    "## Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catFeats = df.dtypes[df.dtypes == 'object'].index.tolist()\n",
    "\n",
    "def catFeat(df):\n",
    "    return df[catFeats]\n",
    "\n",
    "keepCat = FunctionTransformer(catFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('VarietyColNLPClean',mapper),\n",
    "    ('ohc',OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('to_dense',ToDenseTransformer()),\n",
    "    ('pca',PCA())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very usefull pipeline visualization\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "pipeline"
   ]
  },
  {
   "source": [
    "## Hyperparameter tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import BayesianRidge, Lasso, Ridge\n",
    "regressors = [BayesianRidge(),Lasso(), Ridge()]\n",
    "# hyperparameter tuning for the Randomized Search\n",
    "params = [{'regressors':[BayesianRidge()],\n",
    "'regressors__n_iter' : [x for x in np.linspace(start=300,stop =1000,num=8)],\n",
    "'regressors__alpha_1' : [round(x,2) for x in np.linspace(start=0.01,stop =1,num=8)],\n",
    "# 'pipeline__pca__n_components': [round(x) for x in np.linspace(start=3,stop = 100,num=8)]\n",
    "},\n",
    "{'regressors':[Lasso()],\n",
    "'regressors__alpha' : [round(x,2) for x in np.linspace(start=0.01,stop =1,num=8)],\n",
    "# preprocessing pipeline\n",
    "# 'pipeline__pca__n_components': [round(x) for x in np.linspace(start=3,stop = 100,num=8)]\n",
    "},\n",
    "\n",
    "{'regressors':[Ridge()],\n",
    "'regressors__alpha' : [round(x,2) for x in np.linspace(start=0.01,stop =1,num=8)],\n",
    "# preprocessing pipeline\n",
    "# 'pipeline__pca__n_components':[round(x) for x in np.linspace(start=3,stop = 100,num=8)]\n",
    "}]\n",
    "# if looking for specific parameters use the get_params methods (e.g.Lasso().get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split of the datasla\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,Y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = Pipeline([('categories', pipeline),\n",
    "                      ('regressors', regressors[0])])\n",
    "baseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline['pca'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tunedModel = RandomizedSearchCV(baseModel,params,verbose=1,n_iter=150, cv=5,random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model score training data: %.3f\" % tunedModel.score(X_train, y_train)) \n",
    "print(\"model score test data: %.3f\" % tunedModel.score(X_test, y_test))\n",
    "print(tunedModel.best_estimator_.get_params)\n",
    "tunedModel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tunedModel.predict(X_test)\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot([y_test,y_pred]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/henri/Documents/Post Lighthouse-Lab work/KaggleML/ramen-ratings/src/models'"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "modelPath = os.path.abspath('../src/models/')\n",
    "filename = 'veryBasicModelMK1.sav'\n",
    "modelPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(tunedModel, open(f'{modelPath}/{filename}', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(f'{modelPath}/{filename}', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-23230626bab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot([y_test,y_pred]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRandoData ={ \n",
    "    'Brand':'Master Kong',\n",
    "    'Variety':'Onion Soy sauce sour kimchi prawn ramyun',\n",
    "    'Style':'cup',\n",
    "    'Country': 'Japan'\n",
    "}\n",
    "newSeries = pd.Series(newRandoData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomNoods():\n",
    "    nood = [random.choice(df[i]) for i in df.columns.to_list()]\n",
    "    print(nood)\n",
    "    return nood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4.29577195])"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "loaded_model.predict([newSeries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict([randomNoods()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropDownVals = {\n",
    "    'Brand' : df.Brand.unique().tolist(),\n",
    "    'Style' : df.Style.unique().tolist(),\n",
    "    'Country' : df.Country.unique().tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFilename = 'DjangoRamenMLDropDownVals'\n",
    "with open(f'{modelPath}/{jsonFilename}.json', 'w') as fp:\n",
    "    json.dump(dropDownVals, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}